{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Compression methods Snappy vs Gzip**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  **Snappy**\n",
    "    * **Low cpu utilization** - It won't occupy many resources. which means other process can get more resources. \n",
    "    * **Low compression** - means lets say we ahve fiel of 1GB than it can compress file to 500MB only. Thus snappy compressed file will occupy more space. \n",
    "    * **Spitable** - in parallel processing the file should be spiltable than only multiple core can access the splited file for computation.\n",
    "    * **use case** - Hot layer - if the compresse data need to be accessed frequently than it is called hot layer are data is accessed multiple time. As the snappy takes less resources thus other processes which are running under same server gets more reosuces for computation. \n",
    "       * But if for hot layer we use gzip than as it takes more resources other processes may get less resources thus for hot layer snappy is used.\n",
    "    * **Use case** - compute intensive - as we know snappy compressed file is spitable whihc means using parallel processing we can get the result in fast. Thus wehre computation need is more we use the snappy.\n",
    "  \n",
    "*  **Gzip**\n",
    "    * **High cpu utilization** - It occupy more resources of a server. which means other process get less resources.  \n",
    "    * **High compression** - means lets say we ahve fiel of 1GB than it can compress file to 200MB \n",
    "    * **Non-Spitable** - Thus only one core can access the file at a time fot computation. \n",
    "    * **use case** - Cold layer - It we don't have to access the data frequently, it is mainly for storage purpose than we can go with gzip compression.\n",
    "    * **Use case** - Storage intensive -   Menas if we need to store the data for longer time or data size is large than we can use the gzip compression as it compresses the file to greater extant. As it occupy lesser memory space thus we use gzip in that case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note - code in databricks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.config(\"spark.driver.host\",'localhost').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName(\"server\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvDF= spark.read.format('csv').options(inferschema=True,header=True,sep=',').load(\"2011-12-05.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Write dataframe in compressed file using snappy compression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvDF=csvDF.filter(csvDF.InvoiceNo>580538)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvDF.write.format('parquet').option(\"compression\",\"snappy\").save(\"/snappy_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Write dataframe in compressed file using gzip compression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvDF.write.format(\"parquet\").option(\"compression\",\"gzip\").save(\"/gzip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
